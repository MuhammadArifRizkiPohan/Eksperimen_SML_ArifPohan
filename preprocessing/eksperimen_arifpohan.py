# -*- coding: utf-8 -*-
"""Eksperimen_ArifPohan

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1nlOFyOD3wqKx8SGgZgSGbw6JnJ6EzzPl

# **1. Perkenalan Dataset**

Dataset Heart Disease

Dataset yang digunakan pada tahap eksperimen ini adalah Heart Disease Dataset, yaitu dataset tabular yang bertujuan untuk memprediksi kemungkinan seseorang mengalami penyakit jantung berdasarkan sejumlah atribut medis dan demografis.

Dataset memiliki beberapa fitur numerik dan kategorikal yang merepresentasikan kondisi pasien, antara lain:

age : Usia pasien

sex : Jenis kelamin (1 = laki-laki, 0 = perempuan)

cp : Tipe nyeri dada

trestbps : Tekanan darah saat istirahat

chol : Kadar kolesterol serum

fbs : Gula darah puasa

restecg : Hasil elektrokardiografi saat istirahat

thalach : Detak jantung maksimum yang dicapai

exang : Angina akibat olahraga

oldpeak : Depresi segmen ST akibat olahraga

slope : Kemiringan segmen ST

ca : Jumlah pembuluh darah utama

thal : Kondisi thalassemia


Label yaitu Menunjukkan kondisi penyakit jantung pasien:

0 → Tidak memiliki penyakit jantung

1 → Memiliki penyakit jantung

# **2. Import Library**

Pada tahap ini, Anda perlu mengimpor beberapa pustaka (library) Python yang dibutuhkan untuk analisis data dan pembangunan model machine learning atau deep learning.
"""

#Type your code here
import pandas as pd
import numpy as np


import matplotlib.pyplot as plt
import seaborn as sns

from sklearn.preprocessing import StandardScaler

"""# **3. Memuat Dataset**

Pada tahap ini, Anda perlu memuat dataset ke dalam notebook. Jika dataset dalam format CSV, Anda bisa menggunakan pustaka pandas untuk membacanya. Pastikan untuk mengecek beberapa baris awal dataset untuk memahami strukturnya dan memastikan data telah dimuat dengan benar.

Jika dataset berada di Google Drive, pastikan Anda menghubungkan Google Drive ke Colab terlebih dahulu. Setelah dataset berhasil dimuat, langkah berikutnya adalah memeriksa kesesuaian data dan siap untuk dianalisis lebih lanjut.

Jika dataset berupa unstructured data, silakan sesuaikan dengan format seperti kelas Machine Learning Pengembangan atau Machine Learning Terapan
"""

#Type your code here
import pandas as pd

# Memuat dataset heart disease (raw)
df = pd.read_csv("/content/heart.csv")

# Menampilkan 5 data teratas
df.head()

"""# **4. Exploratory Data Analysis (EDA)**

Pada tahap ini, Anda akan melakukan **Exploratory Data Analysis (EDA)** untuk memahami karakteristik dataset.

Tujuan dari EDA adalah untuk memperoleh wawasan awal yang mendalam mengenai data dan menentukan langkah selanjutnya dalam analisis atau pemodelan.
"""

# Menampilkan informasi struktur dataset
df.info()

# Menampilkan jumlah baris dan kolom
df.shape

#Menampilkan ringkasan statistik dari setiap fitur numerik pada dataset.
df.describe()

#memeriksa missing value
df.isnull().sum()

#Korelasi antar fitur
plt.figure(figsize=(10,6))
sns.heatmap(df.corr(), annot=True, cmap="coolwarm")
plt.title("Heatmap Korelasi Fitur")
plt.show()

"""# **5. Data Preprocessing**

Pada tahap ini, data preprocessing adalah langkah penting untuk memastikan kualitas data sebelum digunakan dalam model machine learning.

Jika Anda menggunakan data teks, data mentah sering kali mengandung nilai kosong, duplikasi, atau rentang nilai yang tidak konsisten, yang dapat memengaruhi kinerja model. Oleh karena itu, proses ini bertujuan untuk membersihkan dan mempersiapkan data agar analisis berjalan optimal.

Berikut adalah tahapan-tahapan yang bisa dilakukan, tetapi **tidak terbatas** pada:
1. Menghapus atau Menangani Data Kosong (Missing Values)
2. Menghapus Data Duplikat
3. Normalisasi atau Standarisasi Fitur
4. Deteksi dan Penanganan Outlier
5. Encoding Data Kategorikal
6. Binning (Pengelompokan Data)

Cukup sesuaikan dengan karakteristik data yang kamu gunakan yah. Khususnya ketika kami menggunakan data tidak terstruktur.
"""

#Data duplikat
df.duplicated().sum()
df = df.drop_duplicates()

#Mengecek Outlier
num_cols = ["age", "trestbps", "chol", "thalach"]

plt.figure(figsize=(12,6))
for i, col in enumerate(num_cols, 1):
    plt.subplot(2, 2, i)
    sns.boxplot(y=df[col])
    plt.title(f"Boxplot {col}")

plt.tight_layout()
plt.show()

def cek_outlier_iqr(data, column):
    Q1 = data[column].quantile(0.25)
    Q3 = data[column].quantile(0.75)
    IQR = Q3 - Q1

    lower = Q1 - 1.5 * IQR
    upper = Q3 + 1.5 * IQR

    outlier = data[(data[column] < lower) | (data[column] > upper)]
    return len(outlier), lower, upper

for col in num_cols:
    jumlah, lower, upper = cek_outlier_iqr(df, col)
    print(f"{col}: {jumlah} outlier (batas {lower:.2f} - {upper:.2f})")

outlier_cols = ["trestbps", "chol", "thalach"]

for col in outlier_cols:
    Q1 = df[col].quantile(0.25)
    Q3 = df[col].quantile(0.75)
    IQR = Q3 - Q1

    lower = Q1 - 1.5 * IQR
    upper = Q3 + 1.5 * IQR

    df[col] = df[col].clip(lower=lower, upper=upper)

#merepresentasikan setiap kategori sebagai fitur biner.
categorical_cols = ["cp", "restecg", "slope", "thal"]

df = pd.get_dummies(
    df,
    columns=categorical_cols,
    drop_first=True
)

#Pemisahn fitur dan target
X = df.drop("target", axis=1)
y = df["target"]

#Standardisasi fitur
from sklearn.preprocessing import StandardScaler

scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

df_preprocessed = pd.DataFrame(
    X_scaled,
    columns=X.columns
)

df_preprocessed["target"] = y.values

#Menyimpan dataset yg telah bersih
df_preprocessed.to_csv(
    "/content/heart_clean.csv",
    index=False
)